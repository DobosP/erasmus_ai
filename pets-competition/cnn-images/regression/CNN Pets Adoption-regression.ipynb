{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional Neural Network\n",
    " \n",
    "# Installing Theano\n",
    "# pip install --upgrade --no-deps git+git://github.com/Theano/Theano.git\n",
    " \n",
    "# Installing Tensorflow\n",
    "# Install Tensorflow from the website: https://www.tensorflow.org/versions/r0.12/get_started/os_setup.html\n",
    " \n",
    "# Installing Keras\n",
    "# pip install --upgrade keras\n",
    "\n",
    "#IMAGES_PATH = 'C:/Users/madad/Documents/dataset/images/training/'\n",
    "RESIZED_IMAGES_PATH = 'C:/Users/madad/Documents/dataset/images/resized/'\n",
    "CSV_PATH = 'C:/Users/madad/Documents/dataset/train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Part 1 - Building the Models\n",
    " \n",
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "# Multilayer Perceptron\n",
    "#-----------------------------------------------------------------------------\n",
    "def create_mlp(dim, regress=False):\n",
    "    # define our MLP network\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_dim=dim, activation=\"relu\"))\n",
    "    model.add(Dense(4, activation=\"relu\"))\n",
    "\n",
    "    # check to see if the regression node should be added\n",
    "    if regress:\n",
    "        model.add(Dense(1, activation=\"linear\"))\n",
    "\n",
    "    # return our model\n",
    "    return model\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "# Regression-based CNN\n",
    "#-----------------------------------------------------------------------------\n",
    "def create_cnn(width, height, depth, filters=(16, 32, 64), regress=False):\n",
    "    # initialize the input shape and channel dimension, assuming\n",
    "    # TensorFlow/channels-last ordering\n",
    "    inputShape = (height, width, depth)\n",
    "    chanDim = -1\n",
    "\n",
    "    # define the model input\n",
    "    inputs = Input(shape=inputShape)\n",
    "\n",
    "    # loop over the number of filters\n",
    "    for (i, f) in enumerate(filters):\n",
    "        # if this is the first CONV layer then set the input\n",
    "        # appropriately\n",
    "        if i == 0:\n",
    "            x = inputs\n",
    "\n",
    "        # Step 1 - Convolution\n",
    "        x = Conv2D(f, (3, 3), padding=\"same\")(x)\n",
    "        \n",
    "        # Step 2 - RELU\n",
    "        x = Activation(\"relu\")(x)\n",
    "        \n",
    "        # Step 3 - BN\n",
    "        x = BatchNormalization(axis=chanDim)(x)\n",
    "        \n",
    "        # Step 4 - Pooling\n",
    "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    # Step 5 - Flattening\n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    # Step 6 - FC layer\n",
    "    x = Dense(16)(x)\n",
    "    \n",
    "    # Step 7 - RELU\n",
    "    x = Activation(\"relu\")(x)\n",
    "    \n",
    "    # Step 8 - BN\n",
    "    x = BatchNormalization(axis=chanDim)(x)\n",
    "    \n",
    "    # Step 9 - DROPOUT\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    # Step 10 - apply another FC layer, this one to match the number of nodes\n",
    "    # coming out of the MLP\n",
    "    x = Dense(4)(x)\n",
    "    \n",
    "    # Step 11 - RELU\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    # check to see if the regression node should be added\n",
    "    if regress:\n",
    "        x = Dense(1, activation=\"linear\")(x)\n",
    "\n",
    "    # construct the CNN\n",
    "    model = Model(inputs, x)\n",
    "    \n",
    "    print(model.summary())\n",
    "\n",
    "    # return the CNN\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this method if your images are not resized\n",
    "# def resize_image(source_path, dest_path):\n",
    "#     image = Image.open(source_path).convert('RGB')\n",
    "#     resized_image = image.resize((IMAGE_SIZE, IMAGE_SIZE))\n",
    "\n",
    "#     # Uncomment to save to local directory \n",
    "#     # Get image name\n",
    "#     name=os.path.basename(source_path)\n",
    "#     resized_image.save(dest_path + name, \"JPEG\")\n",
    "\n",
    "#     # new_image size (64,64)\n",
    "#     return np.asarray(resized_image)\n",
    "\n",
    "# def load_resize_pet_images(df, source, destination):    \n",
    "#     # initialize images array \n",
    "#     images = []\n",
    "    \n",
    "#     # loop over the csv rows\n",
    "#     for index, row in df.iterrows():\n",
    "        \n",
    "#         img_source = source + row['PetID'] + '.jpg'\n",
    "    \n",
    "#         resized = resize_image(img_source, destination)\n",
    "        \n",
    "#         # add the image to the set of images the network will be trained on\n",
    "#         images.append(resized)\n",
    "        \n",
    "#     # return our set of images\n",
    "#     return np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import io\n",
    "import os\n",
    "\n",
    "IMAGE_SIZE = 64\n",
    "\n",
    "def read_image(path):\n",
    "    image = Image.open(path).convert('RGB')\n",
    "    return np.asarray(image)\n",
    "\n",
    "def load_pet_images(df, inputDir):    \n",
    "    # initialize images array \n",
    "    images = []\n",
    "\n",
    "    # loop over the csv rows\n",
    "    for index, row in df.iterrows():\n",
    "        \n",
    "        img_path = inputDir + row['PetID'] + '.jpg'\n",
    "    \n",
    "        img = read_image(img_path)\n",
    "        \n",
    "        # add the image to the set of images the network will be trained on\n",
    "        images.append(img)\n",
    "    \n",
    "    # return our set of images\n",
    "    return np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from random import shuffle\n",
    "import glob\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "def process_csv(df):\n",
    "    new_df = pd.DataFrame() \n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        \n",
    "        quantity = int(row['PhotoAmt'])\n",
    "        \n",
    "        if (not re.match(\"^[a-zA-Z0-9_]*$\", row['PetID'])):\n",
    "            print(row['PetID'])\n",
    "            continue\n",
    "    \n",
    "        petId = str(row['PetID'])\n",
    "        \n",
    "        for i in range(1, quantity+1):\n",
    "            new_row = row\n",
    "            new_row['PetID'] = petId + '-' + str(i)\n",
    "            \n",
    "            new_df = new_df.append([new_row],ignore_index=True)\n",
    "            \n",
    "    return new_df\n",
    "    \n",
    "def load_pet_attributes(inputPath):\n",
    "    # initialize the list of column names in the CSV file and then\n",
    "    # load it using Pandas\n",
    "    cols = [\"Type\", \"Name\", \"Age\", \"Breed1\", \"Breed2\", \"Gender\", \"Color1\", \"Color2\", \"Color3\", \"MaturitySize\", \"FurLength\", \"Vaccinated\", \"Dewormed\", \"Sterilized\", \"Health\", \"Quantity\", \"Fee\", \"State\", \"RescuerID\", \"VideoAmt\", \"Description\", \"PetID\", \"PhotoAmt\", \"AdoptionSpeed\"]\n",
    "    df = pd.read_csv(inputPath, header=0, usecols=['PhotoAmt', 'PetID', 'AdoptionSpeed'], names=cols)\n",
    "    \n",
    "    df = process_csv(df)\n",
    "\n",
    "    # return the data frame\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading pet features...\n",
      "[INFO] processed features\n"
     ]
    }
   ],
   "source": [
    "#-----------------------------------------------------------------------------\n",
    "# Load pet features from csv\n",
    "#-----------------------------------------------------------------------------\n",
    "# construct the path to the train.csv file that contains information\n",
    "# on each pet in the dataset and then load the dataset\n",
    "print(\"[INFO] loading pet features...\")\n",
    "df = load_pet_attributes(CSV_PATH)\n",
    "print(\"[INFO] processed features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading pet images...\n",
      "[INFO] processed images\n"
     ]
    }
   ],
   "source": [
    "#-----------------------------------------------------------------------------\n",
    "# Load the pet images\n",
    "#-----------------------------------------------------------------------------\n",
    "# scale the pixel intensities to the range [0, 1]\n",
    "print(\"[INFO] loading pet images...\")\n",
    "images = load_pet_images(df, RESIZED_IMAGES_PATH)\n",
    "images = images / 255.0\n",
    "print(\"[INFO] processed images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------------------------\n",
    "# Split data into training and testing sets\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "import locale\n",
    "\n",
    "# partition the data into training and testing splits using 90% of\n",
    "# the data for training and the remaining 10% for testing\n",
    "split = train_test_split(df, images, test_size=0.1, random_state=42)\n",
    "(trainAttrX, testAttrX, trainImagesX, testImagesX) = split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the pet adoption speed to the range [0, 1] (will lead to better\n",
    "# training and convergence)\n",
    "# the largest pet adoption value is 4 \n",
    "maxAdoption = 4\n",
    "trainY = trainAttrX[\"AdoptionSpeed\"] / maxAdoption\n",
    "testY = testAttrX[\"AdoptionSpeed\"] / maxAdoption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------------------------\n",
    "# Define custom loss functions for regression in Keras \n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "# root mean squared error (rmse) for regression\n",
    "def rmse(y_true, y_pred):\n",
    "    from keras import backend\n",
    "    return backend.sqrt(backend.mean(backend.square(y_pred - y_true), axis=-1))\n",
    "\n",
    "# mean squared error (mse) for regression\n",
    "def mse(y_true, y_pred):\n",
    "    from keras import backend\n",
    "    return backend.mean(backend.square(y_pred - y_true), axis=-1)\n",
    "\n",
    "# coefficient of determination (R^2) for regression\n",
    "def r_square(y_true, y_pred):\n",
    "    from keras import backend as K\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    return (1 - SS_res/(SS_tot + K.epsilon()))\n",
    "\n",
    "def r_square_loss(y_true, y_pred):\n",
    "    from keras import backend as K\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    return 1 - ( 1 - SS_res/(SS_tot + K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 16)        448       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 64, 64, 16)        64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 32)        4640      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                65552     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 89,721\n",
      "Trainable params: 89,465\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "None\n",
      "[INFO] training model...\n",
      "Train on 52479 samples, validate on 5832 samples\n",
      "Epoch 1/10\n",
      "52479/52479 [==============================] - 666s 13ms/step - loss: 0.1851 - mean_squared_error: 0.1851 - rmse: 0.3229 - r_square: -1.4478 - val_loss: 0.0807 - val_mean_squared_error: 0.0807 - val_rmse: 0.2440 - val_r_square: -0.0558\n",
      "Epoch 2/10\n",
      "52479/52479 [==============================] - 644s 12ms/step - loss: 0.0820 - mean_squared_error: 0.0820 - rmse: 0.2453 - r_square: -0.0751 - val_loss: 0.0786 - val_mean_squared_error: 0.0786 - val_rmse: 0.2412 - val_r_square: -0.0279\n",
      "Epoch 3/10\n",
      "52479/52479 [==============================] - 619s 12ms/step - loss: 0.0793 - mean_squared_error: 0.0793 - rmse: 0.2440 - r_square: -0.0426 - val_loss: 0.0784 - val_mean_squared_error: 0.0784 - val_rmse: 0.2429 - val_r_square: -0.0257\n",
      "Epoch 4/10\n",
      "52479/52479 [==============================] - 632s 12ms/step - loss: 0.0793 - mean_squared_error: 0.0793 - rmse: 0.2444 - r_square: -0.0412 - val_loss: 0.0807 - val_mean_squared_error: 0.0807 - val_rmse: 0.2459 - val_r_square: -0.0541\n",
      "Epoch 5/10\n",
      "52479/52479 [==============================] - 686s 13ms/step - loss: 0.0796 - mean_squared_error: 0.0796 - rmse: 0.2455 - r_square: -0.0439 - val_loss: 0.0789 - val_mean_squared_error: 0.0789 - val_rmse: 0.2450 - val_r_square: -0.0304\n",
      "Epoch 6/10\n",
      "52479/52479 [==============================] - 689s 13ms/step - loss: 0.0791 - mean_squared_error: 0.0791 - rmse: 0.2449 - r_square: -0.0363 - val_loss: 0.0787 - val_mean_squared_error: 0.0787 - val_rmse: 0.2444 - val_r_square: -0.0284\n",
      "Epoch 7/10\n",
      "52479/52479 [==============================] - 677s 13ms/step - loss: 0.0790 - mean_squared_error: 0.0790 - rmse: 0.2448 - r_square: -0.0372 - val_loss: 0.0790 - val_mean_squared_error: 0.0790 - val_rmse: 0.2448 - val_r_square: -0.0324\n",
      "Epoch 8/10\n",
      "52479/52479 [==============================] - 6676s 127ms/step - loss: 0.0790 - mean_squared_error: 0.0790 - rmse: 0.2452 - r_square: -0.0367 - val_loss: 0.0786 - val_mean_squared_error: 0.0786 - val_rmse: 0.2444 - val_r_square: -0.0267\n",
      "Epoch 9/10\n",
      "52479/52479 [==============================] - 1167s 22ms/step - loss: 0.0787 - mean_squared_error: 0.0787 - rmse: 0.2446 - r_square: -0.0320 - val_loss: 0.0791 - val_mean_squared_error: 0.0791 - val_rmse: 0.2448 - val_r_square: -0.0327\n",
      "Epoch 10/10\n",
      "52479/52479 [==============================] - 5282s 101ms/step - loss: 0.0784 - mean_squared_error: 0.0784 - rmse: 0.2438 - r_square: -0.0289 - val_loss: 0.0813 - val_mean_squared_error: 0.0813 - val_rmse: 0.2440 - val_r_square: -0.0659\n",
      "[INFO] traing finished\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "# Compile Keras model\n",
    "#-----------------------------------------------------------------------------\n",
    "# create the Convolutional Neural Network and then compile the model\n",
    "# using mean absolute percentage error as loss, implying that we\n",
    "# seek to minimize the absolute percentage difference between our\n",
    "# adoption speed *predictions* and the *actual adoption speeds*\n",
    "model = create_cnn(64, 64, 3, regress=True)\n",
    "model.compile(optimizer='adam', loss=\"mean_squared_error\", metrics=[\"mean_squared_error\", rmse, r_square])\n",
    "\n",
    "# train the model\n",
    "print(\"[INFO] training model...\")\n",
    "result = model.fit(trainImagesX, trainY, validation_data=(testImagesX, testY),\n",
    "          epochs=10, batch_size=32)\n",
    "print(\"[INFO] traing finished\")\n",
    "\n",
    "# enable early stopping based on mean_squared_error\n",
    "earlystopping = EarlyStopping(monitor=\"mean_squared_error\", patience=40, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plot metrics\n",
    "plt.plot(result.history['mean_squared_error'])\n",
    "plt.plot(result.history['rmse'])\n",
    "plt.plot(result.history['r_square'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_to_disk(model):\n",
    "    # serialize model to JSON\n",
    "    model_json = model.to_json()\n",
    "    with open(model_name + \".json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(model_name + \".h5\")\n",
    "    print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "IMG_SIZE = 64\n",
    "\n",
    "model_name = \"pets_regression{}pixels_{}epochs\".format(IMG_SIZE, EPOCHS)\n",
    "\n",
    "save_model_to_disk(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
