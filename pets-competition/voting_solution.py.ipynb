{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pydot\n",
    "\n",
    "from sklearn.externals.six import StringIO\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "import score_solution\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import cohen_kappa_score, make_scorer\n",
    "\n",
    "\n",
    "\n",
    "train_data = pd.read_csv('all_train_data_V2.csv')\n",
    "test_data = pd.read_csv('all_test_data_V2.csv')\n",
    "\n",
    "adoptionSpeed = train_data['AdoptionSpeed'] \n",
    "del train_data['AdoptionSpeed']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  app.launch_new_instance()\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n"
     ]
    }
   ],
   "source": [
    "test_ids = test_data[['PetID']]\n",
    "\n",
    "del train_data[\"Name\"]\n",
    "del train_data[\"RescuerID\"]\n",
    "del train_data[\"Description\"]\n",
    "del train_data[\"PetID\"]\n",
    "\n",
    "\n",
    "del test_data[\"Name\"]\n",
    "del test_data[\"RescuerID\"]\n",
    "del test_data[\"Description\"]\n",
    "del test_data[\"PetID\"]\n",
    "\n",
    "train_data = train_data.fillna(0)\n",
    "test_data = test_data.fillna(0)\n",
    "train_data = preprocessing.scale(train_data)\n",
    "test_data = preprocessing.scale(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 4, 4, ..., 2, 1, 3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "\n",
    "\n",
    "gbc_model = GradientBoostingClassifier(n_estimators=1100, learning_rate=0.03,\n",
    "     max_depth=2)\n",
    "agb_model = AdaBoostClassifier(algorithm='SAMME.R',\n",
    "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
    "            max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'),\n",
    "          learning_rate=0.03, n_estimators=1100, random_state=None)\n",
    "extra_model = ExtraTreesClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=2, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=None,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False)\n",
    "\n",
    "rf_model = RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
    "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=2, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=None,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False)\n",
    "bagging_model = BaggingClassifier(DecisionTreeClassifier(), n_estimators = 1000,\n",
    "                            max_samples=0.5, max_features=0.5)\n",
    "\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=0.5, gamma=0, learning_rate=0.03, max_delta_step=0,\n",
    "       max_depth=3, min_child_weight=1, missing=None, n_estimators=650,\n",
    "       n_jobs=1, nthread=None, objective='multi:softprob', random_state=0,\n",
    "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "       silent=True, subsample=0.8)\n",
    "\n",
    "classifiers = [\n",
    "    ('gbc', gbc_model), ('agb', agb_model),\n",
    "    ('extra', extra_model), ('rf', rf_model),\n",
    "    ('bagging', bagging_model), (\"xgb\", xgb_model)\n",
    "]\n",
    "\n",
    "voting_model = VotingClassifier(estimators=classifiers, voting='hard')\n",
    "\n",
    "voting_model.fit(train_data, adoptionSpeed)\n",
    "\n",
    "ans = voting_model.predict(test_data)\n",
    "\n",
    "ans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       PetID  AdoptionSpeed\n",
      "0  000c21f80              1\n",
      "1  001d503e8              4\n",
      "2  001ec8d5b              4\n",
      "3  002d58f95              2\n",
      "4  004682b50              4\n"
     ]
    }
   ],
   "source": [
    "submission = pd.DataFrame({'PetID': test_ids['PetID'].values, 'AdoptionSpeed': ans})\n",
    "print(submission.head())\n",
    "submission.to_csv('submission2.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "               learning_rate=0.03, loss='deviance', max_depth=2,\n",
       "               max_features=None, max_leaf_nodes=None,\n",
       "               min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "               min_samples_leaf=1, min_samples_split=2,\n",
       "               min_weight_fraction_leaf=0.0, n_estimators=1100,\n",
       "               n_iter_no_change=None, presort='auto', random_state=None,\n",
       "               subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "               verbose=0, warm_start=False),\n",
       " AdaBoostClassifier(algorithm='SAMME.R',\n",
       "           base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "             splitter='best'),\n",
       "           learning_rate=0.03, n_estimators=1100, random_state=None),\n",
       " ExtraTreesClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=2, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       " RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "             max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=2, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=None,\n",
       "             oob_score=False, random_state=None, verbose=0,\n",
       "             warm_start=False),\n",
       " BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "             splitter='best'),\n",
       "          bootstrap=True, bootstrap_features=False, max_features=0.5,\n",
       "          max_samples=0.5, n_estimators=1000, n_jobs=None, oob_score=False,\n",
       "          random_state=None, verbose=0, warm_start=False),\n",
       " XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "        colsample_bytree=0.5, gamma=0, learning_rate=0.03, max_delta_step=0,\n",
       "        max_depth=3, min_child_weight=1, missing=None, n_estimators=650,\n",
       "        n_jobs=1, nthread=None, objective='multi:softprob', random_state=0,\n",
       "        reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "        silent=True, subsample=0.8)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_model.estimators_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
