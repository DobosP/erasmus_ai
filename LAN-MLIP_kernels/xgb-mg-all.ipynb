{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# Importing core libraries\n",
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "import pprint\n",
    "import joblib\n",
    "import logging\n",
    "\n",
    "\n",
    "# Suppressing warnings because of skopt verbosity\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Boosting models\n",
    "import catboost as cat\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Hyperparameters distributions\n",
    "from scipy.stats import randint\n",
    "from scipy.stats import uniform\n",
    "\n",
    "# Preprocesing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Utilities\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tqdm import tqdm_notebook\n",
    "from itertools import chain\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Model selection\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# Skopt functions\n",
    "from skopt import BayesSearchCV\n",
    "from skopt import gp_minimize # Bayesian optimization using Gaussian Processes\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from skopt.utils import use_named_args # decorator to convert a list of parameters to named arguments\n",
    "from skopt.callbacks import DeadlineStopper # Stop the optimization before running out of a fixed budget of time.\n",
    "from skopt.callbacks import VerboseCallback # Callback to control the verbosity\n",
    "from skopt.callbacks import DeltaXStopper # Stop the optimization If the last two positions at which the objective has been evaluated are less than delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['all-features', 'basic-features', 'LANL-Earthquake-Prediction']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IS_LOCAL = False\n",
    "if(IS_LOCAL):\n",
    "    PATH=\"../input/LANL/\"\n",
    "else:\n",
    "    PATH=\"../input/\"\n",
    "os.listdir(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_train_X = pd.read_csv('../input/all-features/train_X.csv')\n",
    "scaled_test_X = pd.read_csv('../input/all-features/test_X.csv')\n",
    "train_y = pd.read_csv('../input/all-features/train_y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4194, 1620), (2624, 1620), (4194, 1))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_train_X.shape, scaled_test_X.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2624, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('../input/LANL-Earthquake-Prediction/sample_submission.csv', index_col='seg_id')\n",
    "submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting average precision score into a scorer suitable for model selection\n",
    "mse_scoring = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "# Setting a 5-fold stratified cross-validation (note: shuffle=True)\n",
    "# skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)S\n",
    "k_fold = KFold(n_splits=7, shuffle=True, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The objective function to be minimized\n",
    "def make_objective(model, X, y, space, cv, scoring):\n",
    "    # This decorator converts your objective function with named arguments into one that\n",
    "    # accepts a list as argument, while doing the conversion automatically.\n",
    "    @use_named_args(space) \n",
    "    def objective(**params):\n",
    "        model.set_params(**params)\n",
    "        return -np.mean(cross_val_score(model, \n",
    "                                        X, y, \n",
    "                                        cv=cv, \n",
    "                                        n_jobs=-1,\n",
    "                                        scoring=scoring))\n",
    "\n",
    "    return objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgb_bayes_params = best_params\n",
    "\n",
    "xgb_bayes_params = {'colsample_bytree': 0.3706219857878677,\n",
    " 'learning_rate': 0.16624226726409647,\n",
    " 'max_bin': 93400,\n",
    " 'max_depth': 134,\n",
    " 'min_child_samples': 22,\n",
    " 'min_child_weight': 4,\n",
    " 'n_estimators': 8028,\n",
    " 'num_leaves': 27,\n",
    " 'reg_alpha': 1.081049236893711e-05,\n",
    " 'reg_lambda': 1.043686239159047,\n",
    " 'scale_pos_weight': 0.19222548462579486,\n",
    " 'subsample': 0.6941640075502717,\n",
    " 'subsample_for_bin': 375140,\n",
    " 'subsample_freq': 7}\n",
    "params=xgb_bayes_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    metric='mae',\n",
    "    n_jobs=1, \n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "dimensions = [Real(0.01, 1.0, 'log-uniform', name='learning_rate'),\n",
    "              Integer(2, 500, name='num_leaves'),\n",
    "              Integer(0, 500, name='max_depth'),\n",
    "              Integer(0, 200, name='min_child_samples'),\n",
    "              Integer(100, 100000, name='max_bin'),\n",
    "              Real(0.01, 1.0, 'uniform', name='subsample'),\n",
    "              Integer(0, 10, name='subsample_freq'),\n",
    "              Real(0.01, 1.0, 'uniform', name='colsample_bytree'),\n",
    "              Integer(0, 10, name='min_child_weight'),\n",
    "              Integer(100000, 500000, name='subsample_for_bin'),\n",
    "              Real(1e-9, 1000, 'log-uniform', name='reg_lambda'),\n",
    "              Real(1e-9, 1.0, 'log-uniform', name='reg_alpha'),\n",
    "              Real(1e-6, 500, 'log-uniform', name='scale_pos_weight'),\n",
    "              Integer(10, 10000, name='n_estimators')]\n",
    "\n",
    "objective = make_objective(xgb_model,\n",
    "                           scaled_train_X, train_y,\n",
    "                           space=dimensions,\n",
    "                           cv=k_fold,\n",
    "                           scoring=mse_scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypeVar, List, Dict, Tuple\n",
    "PandasDataFrame = TypeVar('pandas.core.frame.DataFrame')\n",
    "\n",
    "def run_xgb(\n",
    "    X_tr: PandasDataFrame,\n",
    "    X_val: PandasDataFrame,\n",
    "    y_tr: PandasDataFrame,\n",
    "    y_val: PandasDataFrame,\n",
    "    test_data: PandasDataFrame,\n",
    "    params: Dict\n",
    "):\n",
    "    \"\"\"CV train lgb Booster.\n",
    "    \n",
    "    Args:\n",
    "        params: Params for Booster.\n",
    "        X_train: Training dataset.\n",
    "        X_test: Testing dataset.\n",
    "        \n",
    "    Returns:\n",
    "        model: Trained model.\n",
    "        oof_train_lgb:  Training CV predictions.\n",
    "        oof_test_lgb:  Testing CV predictions.\n",
    "    \"\"\"\n",
    "    \n",
    "    early_stop = 200\n",
    "    num_rounds = 10000\n",
    "    verbose_eval=1000\n",
    "\n",
    "    d_train = xgb.DMatrix(X_tr.values, label = y_tr)\n",
    "    d_valid = xgb.DMatrix(X_val.values, label = y_val )\n",
    "    d_test = xgb.DMatrix(test_data.values) #+ mg\n",
    "    watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "    \n",
    "    #1st run to get importance\n",
    "    model = xgb.train(params, dtrain=d_train,num_boost_round=num_rounds,evals=watchlist, \n",
    "                      verbose_eval=verbose_eval,early_stopping_rounds=early_stop)    \n",
    "    #importance\n",
    "    imps=model.get_score(importance_type='gain')\n",
    "    f_nums = model.feature_names\n",
    "    f_names = list(scaled_train_X)\n",
    "    f_dict = dict(zip(f_nums,f_names))\n",
    "    keys=[]\n",
    "    for i in imps:\n",
    "        keys.append(f_dict.get(i))\n",
    "    X_tr_new = X_tr.loc[:,keys]\n",
    "    X_val_new=X_val.loc[:,keys]\n",
    "    test_data_new=test_data.loc[:,keys]\n",
    "    \n",
    "    d_train = xgb.DMatrix(X_tr_new.values, label = y_tr)\n",
    "    d_valid = xgb.DMatrix(X_val_new.values, label = y_val )\n",
    "    d_test = xgb.DMatrix(test_data_new.values) #+ mg\n",
    "    watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "    \n",
    "    model = xgb.train(params, dtrain=d_train,num_boost_round=num_rounds,evals=watchlist, \n",
    "                      verbose_eval=verbose_eval,early_stopping_rounds=early_stop) \n",
    "\n",
    "    val_pred = model.predict(d_valid)\n",
    "    prediction = model.predict(d_test)\n",
    "    \n",
    "    return val_pred, prediction\n",
    "\n",
    "def run_cv_model(\n",
    "    train_data,\n",
    "    train_target,\n",
    "    test_data,\n",
    "    model_fn, \n",
    "    params,\n",
    "    eval_fn=None,\n",
    "    label='model',\n",
    "    feature_imp=False,\n",
    "    n_folds = 5\n",
    "):\n",
    "    oof_val = np.zeros(len(train_data))\n",
    "    predictions = np.zeros(len(test_data))\n",
    "    oof_predict = np.zeros((n_folds, test_data.shape[0]))\n",
    "    scores = []\n",
    "\n",
    "   # feature_importance_df = pd.DataFrame()\n",
    "    \n",
    "    folds = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "    train_columns = train_data.columns.values\n",
    "    \n",
    "\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_data, train_target.values)):\n",
    "        strLog = \"fold {} for {}\".format(fold_, label)\n",
    "        print(strLog)\n",
    "        X_tr, X_val = train_data.iloc[trn_idx], train_data.iloc[val_idx]\n",
    "        y_tr, y_val = train_target.iloc[trn_idx], train_target.iloc[val_idx]\n",
    "        \n",
    "        val_pred, prediction= model_fn( #, feature_importances \n",
    "            X_tr, X_val,\n",
    "            y_tr, y_val,\n",
    "            test_data,\n",
    "            params\n",
    "        )\n",
    "        score = mean_squared_error(y_val, val_pred)\n",
    "        scores.append(score)\n",
    "\n",
    "        \n",
    "        oof_val[val_idx] = val_pred\n",
    "        \n",
    "        #feature importance\n",
    "        if feature_imp == True:\n",
    "            fold_importance_df = pd.DataFrame()\n",
    "            fold_importance_df[\"feature\"] = train_columns\n",
    "            fold_importance_df[\"importance\"] = feature_importances[:len(train_columns)]\n",
    "            fold_importance_df[\"fold\"] = fold_ + 1\n",
    "            feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "        \n",
    "        #predictions\n",
    "        oof_predict[fold_] = prediction\n",
    "        predictions += prediction/folds.n_splits\n",
    "        \n",
    "        print('CV score: {0:.4f}, std: {1:.4f}.\\n'.format(np.mean(score), np.std(score)))  \n",
    "        print('CV mean score: {0:.4f}, std: {1:.4f}.\\n'.format(np.mean(scores), np.std(scores)))  \n",
    "\n",
    "\n",
    "            \n",
    "    return oof_val, oof_predict, predictions #, feature_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0 for xgb\n",
      "[0]\ttrain-rmse:5.46787\tvalid-rmse:5.46655\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[17]\ttrain-rmse:0.72412\tvalid-rmse:2.88156\n",
      "\n",
      "[0]\ttrain-rmse:5.46706\tvalid-rmse:5.45773\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[81]\ttrain-rmse:0.034749\tvalid-rmse:2.82291\n",
      "\n",
      "CV score: 7.9754, std: 0.0000.\n",
      "\n",
      "CV mean score: 7.9754, std: 0.0000.\n",
      "\n",
      "fold 1 for xgb\n",
      "[0]\ttrain-rmse:5.44365\tvalid-rmse:5.5933\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[26]\ttrain-rmse:0.355623\tvalid-rmse:2.76044\n",
      "\n",
      "[0]\ttrain-rmse:5.44509\tvalid-rmse:5.58207\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[35]\ttrain-rmse:0.199333\tvalid-rmse:2.69842\n",
      "\n",
      "CV score: 7.3149, std: 0.0000.\n",
      "\n",
      "CV mean score: 7.6451, std: 0.3303.\n",
      "\n",
      "fold 2 for xgb\n",
      "[0]\ttrain-rmse:5.47384\tvalid-rmse:5.30968\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[17]\ttrain-rmse:0.720816\tvalid-rmse:2.80161\n",
      "\n",
      "[0]\ttrain-rmse:5.47677\tvalid-rmse:5.34094\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[15]\ttrain-rmse:0.860098\tvalid-rmse:2.83326\n",
      "\n",
      "CV score: 8.1776, std: 0.0000.\n",
      "\n",
      "CV mean score: 7.8226, std: 0.3684.\n",
      "\n",
      "fold 3 for xgb\n",
      "[0]\ttrain-rmse:5.44164\tvalid-rmse:5.69953\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[108]\ttrain-rmse:0.01973\tvalid-rmse:2.9254\n",
      "\n",
      "[0]\ttrain-rmse:5.43038\tvalid-rmse:5.69115\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[45]\ttrain-rmse:0.108264\tvalid-rmse:2.86646\n",
      "\n",
      "CV score: 8.2376, std: 0.0000.\n",
      "\n",
      "CV mean score: 7.9264, std: 0.3662.\n",
      "\n",
      "fold 4 for xgb\n",
      "[0]\ttrain-rmse:5.47826\tvalid-rmse:5.3658\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[28]\ttrain-rmse:0.306847\tvalid-rmse:2.91022\n",
      "\n",
      "[0]\ttrain-rmse:5.48606\tvalid-rmse:5.31716\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[22]\ttrain-rmse:0.475925\tvalid-rmse:2.68098\n",
      "\n",
      "CV score: 7.2059, std: 0.0000.\n",
      "\n",
      "CV mean score: 7.7823, std: 0.4363.\n",
      "\n",
      "fold 5 for xgb\n",
      "[0]\ttrain-rmse:5.45102\tvalid-rmse:5.58185\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[40]\ttrain-rmse:0.157776\tvalid-rmse:2.72549\n",
      "\n",
      "[0]\ttrain-rmse:5.44705\tvalid-rmse:5.51658\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[28]\ttrain-rmse:0.305669\tvalid-rmse:2.7229\n",
      "\n",
      "CV score: 7.4543, std: 0.0000.\n",
      "\n",
      "CV mean score: 7.7276, std: 0.4166.\n",
      "\n",
      "fold 6 for xgb\n",
      "[0]\ttrain-rmse:5.42928\tvalid-rmse:5.75734\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[38]\ttrain-rmse:0.160175\tvalid-rmse:2.69279\n",
      "\n",
      "[0]\ttrain-rmse:5.42142\tvalid-rmse:5.79718\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[76]\ttrain-rmse:0.05408\tvalid-rmse:2.73168\n",
      "\n",
      "CV score: 7.4663, std: 0.0000.\n",
      "\n",
      "CV mean score: 7.6903, std: 0.3964.\n",
      "\n",
      "fold 7 for xgb\n",
      "[0]\ttrain-rmse:5.44493\tvalid-rmse:5.50712\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[28]\ttrain-rmse:0.3179\tvalid-rmse:2.6285\n",
      "\n",
      "[0]\ttrain-rmse:5.4525\tvalid-rmse:5.47155\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[21]\ttrain-rmse:0.526585\tvalid-rmse:2.53347\n",
      "\n",
      "CV score: 6.4609, std: 0.0000.\n",
      "\n",
      "CV mean score: 7.5366, std: 0.5503.\n",
      "\n",
      "fold 8 for xgb\n",
      "[0]\ttrain-rmse:5.43021\tvalid-rmse:5.70252\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[40]\ttrain-rmse:0.168937\tvalid-rmse:2.88955\n",
      "\n",
      "[0]\ttrain-rmse:5.43613\tvalid-rmse:5.70599\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[23]\ttrain-rmse:0.43848\tvalid-rmse:2.77261\n",
      "\n",
      "CV score: 7.7271, std: 0.0000.\n",
      "\n",
      "CV mean score: 7.5578, std: 0.5222.\n",
      "\n",
      "fold 9 for xgb\n",
      "[0]\ttrain-rmse:5.45469\tvalid-rmse:5.5605\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[25]\ttrain-rmse:0.370642\tvalid-rmse:2.83525\n",
      "\n",
      "[0]\ttrain-rmse:5.44818\tvalid-rmse:5.56575\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[47]\ttrain-rmse:0.117733\tvalid-rmse:2.92801\n",
      "\n",
      "CV score: 8.5791, std: 0.0000.\n",
      "\n",
      "CV mean score: 7.6599, std: 0.5825.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fix_xgb_params = {\n",
    "    \"boosting\": \"gblinear\",\n",
    "    \"metric\": 'mae',\n",
    "}\n",
    "\n",
    "xgb_params = {**fix_xgb_params, **xgb_bayes_params}\n",
    "\n",
    "\n",
    "oof_val, oof_predict, predictions  = run_cv_model( #extra param: '', feature_importance_df'''\n",
    "    train_data=scaled_train_X,\n",
    "    train_target=train_y,\n",
    "    test_data=scaled_test_X,\n",
    "    model_fn=run_xgb,\n",
    "    params=xgb_params,\n",
    "    eval_fn=None,\n",
    "    label=\"xgb\",\n",
    "    feature_imp=False,\n",
    "    n_folds=10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.time_to_failure = predictions\n",
    "submission.to_csv('submission.csv',index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
