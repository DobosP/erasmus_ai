{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These features are an indicatory factors about the Image Quality. Following is the list of features:\n",
    "\n",
    "1. Dullness : Is the Image Very Dull ?\n",
    "1.1 Image Dullness Score\n",
    "\n",
    "2. Whiteness : Is the Image Very White ?\n",
    "2.1 Image Whiteness Score\n",
    "\n",
    "3. Uniformity : Is the Image too Uniform ?\n",
    "3.1 Average Pixel Width\n",
    "\n",
    "4. Colors : What are the top colors used in the Image ?\n",
    "4.1 Dominant Color of the Image\n",
    "4.2 Average Color of the Image\n",
    "\n",
    "5. Dimensions : Is the Image too Large or too Small ?\n",
    "5.1 Width of the Image\n",
    "5.2 Height of the Image\n",
    "5.3 Size of the Image\n",
    "\n",
    "6. Blurrness : Is the Image Too Blurry ?\n",
    "6.1 Width of the Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "ccdc873b-d98f-40c8-939c-9725a74f262c",
    "_kg_hide-input": true,
    "_uuid": "5768a3c8f6f633403efdcce8398ac3eaa74ebde1",
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from scipy.stats import itemfreq\n",
    "from scipy import ndimage as ndi\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import feature\n",
    "from PIL import Image as IMG\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import operator\n",
    "#import cv2\n",
    "import os \n",
    "\n",
    "from IPython.core.display import HTML \n",
    "from IPython.display import Image\n",
    "\n",
    "images_path = 'C:/Users/madad/Documents/dataset/images/resized/'\n",
    "original_images_path = 'C:/Users/madad/Documents/dataset/images/training/'\n",
    "imgs = os.listdir(images_path)\n",
    "features = pd.DataFrame()\n",
    "features['image'] = imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ca91d69c-1652-4565-a167-7d8f0e6cb678",
    "_uuid": "1d372df765926103668eeaa3e1b35e6cc9f0debf",
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 6,
        "hidden": false,
        "row": 37,
        "width": 12
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "## 1. Is the image Very Dull \n",
    "\n",
    "### Feature 1 : Dullness\n",
    "\n",
    "Dull Images may not be good for the advertisment purposes. The analysis of prominent colors present in the images can indicate a lot about if the image is dull or not. In the following cell, there is the code to measure the dullness score of the image which can be used as one of the feature in the model. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "459760ce-8324-48a3-ba03-a2a38d20fea7",
    "_uuid": "e20c9c69fd613f94e3b4b94a290d59776603f5a1",
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def color_analysis(img):\n",
    "    # obtain the color palatte of the image \n",
    "    palatte = defaultdict(int)\n",
    "    for pixel in img.getdata():\n",
    "        palatte[pixel] += 1\n",
    "    \n",
    "    # sort the colors present in the image \n",
    "    sorted_x = sorted(palatte.items(), key=operator.itemgetter(1), reverse = True)\n",
    "    light_shade, dark_shade, shade_count, pixel_limit = 0, 0, 0, 25\n",
    "    for i, x in enumerate(sorted_x[:pixel_limit]):\n",
    "        if all(xx <= 20 for xx in x[0][:3]): ## dull : too much darkness \n",
    "            dark_shade += x[1]\n",
    "        if all(xx >= 240 for xx in x[0][:3]): ## bright : too much whiteness \n",
    "            light_shade += x[1]\n",
    "        shade_count += x[1]\n",
    "        \n",
    "    light_percent = round((float(light_shade)/shade_count)*100, 2)\n",
    "    dark_percent = round((float(dark_shade)/shade_count)*100, 2)\n",
    "    return light_percent, dark_percent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "48e163bf-c867-43b9-b61f-22aece750aaa",
    "_uuid": "d9b6724b5fdb52cf9a7504012337017d49c49344",
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 4,
        "hidden": false,
        "row": 43,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "Lets compute the dull score for the sample images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "2b547611-5247-4424-b05d-02c87750c669",
    "_uuid": "f3cec207d871a5188fe4f78dc049af477b873981",
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 7,
        "hidden": false,
        "row": 43,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def perform_color_analysis(img, flag):    \n",
    "    path = images_path + img \n",
    "    im = IMG.open(path) #.convert(\"RGB\")\n",
    "    \n",
    "    # cut the images into two halves as complete average may give bias results\n",
    "    size = im.size\n",
    "    halves = (size[0]/2, size[1]/2)\n",
    "    im1 = im.crop((0, 0, size[0], halves[1]))\n",
    "    im2 = im.crop((0, halves[1], size[0], size[1]))\n",
    "\n",
    "    try:\n",
    "        light_percent1, dark_percent1 = color_analysis(im1)\n",
    "        light_percent2, dark_percent2 = color_analysis(im2)\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "    light_percent = (light_percent1 + light_percent2)/2 \n",
    "    dark_percent = (dark_percent1 + dark_percent2)/2 \n",
    "    \n",
    "    if flag == 'black':\n",
    "        return dark_percent\n",
    "    elif flag == 'white':\n",
    "        return light_percent\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e36b0c53-d99b-41b7-a9b5-b3133e77f73f",
    "_kg_hide-input": true,
    "_uuid": "c4685c6501071e90cbd70f2476e97cd9d8cdd596"
   },
   "outputs": [],
   "source": [
    "features['dullness'] = features['image'].apply(lambda x : perform_color_analysis(x, 'black'))\n",
    "topdull = features.sort_values('dullness', ascending = False)\n",
    "topdull.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0e009ae9-f83f-4a42-8bf7-eeeadd6ef331",
    "_uuid": "b392a3958d5fab56539a0ae1350fd23d8afb7de7",
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 4,
        "hidden": false,
        "row": 43,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "Lets plot some of the images with very high dullness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ceac13b7-f269-477c-9598-db0948aba06a",
    "_kg_hide-input": true,
    "_uuid": "88f5ca1819a615a208489c1c29c04090b3fbe449",
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 24,
        "hidden": false,
        "row": 47,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "for j,x in topdull.head(2).iterrows():\n",
    "    path = images_path + x['image']\n",
    "    html = \"<h4>Image : \"+x['image']+\" &nbsp;&nbsp;&nbsp; (Dullness : \" + str(x['dullness']) +\")</h4>\"\n",
    "    display(HTML(html))\n",
    "    display(IMG.open(path).resize((300,300), IMG.ANTIALIAS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "cc5a68d1-be44-4cbb-9da7-a4f6446ad2d0",
    "_uuid": "6ac2621912480b3ac85ac298f5199de725d3519d",
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 6,
        "hidden": false,
        "row": 71,
        "width": 12
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "## 2. Is the Image too bright or white \n",
    "\n",
    "### Feature 2 : Image Whiteness\n",
    "\n",
    "Some images can be too white or too bright which might not be good for the advertisement purposes. Using the samy type of color analysis, we can check if the images are too white. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "359b7df1-fd85-4ca6-ab7b-33ee28c1e9f3",
    "_uuid": "41320793876b85cdde8cd7184d21fda98268b5f0",
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 7,
        "hidden": false,
        "row": 47,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "features['whiteness'] = features['image'].apply(lambda x : perform_color_analysis(x, 'white'))\n",
    "topdull = features.sort_values('whiteness', ascending = False)\n",
    "topdull.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1b6cae3a-5d7f-40e3-8833-bdd697a8ea22",
    "_uuid": "b95ef5abf56433113bf1a0e99882cbdc9f0bcbad",
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 50,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "Lets plot some of the images having high whiteness score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b23796d6-f646-4dab-adef-eb432b27a5f0",
    "_kg_hide-input": true,
    "_uuid": "725452854350e7cb163a6cd50ff8b033ca0221c1",
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 24,
        "hidden": false,
        "row": 77,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "for j,x in topdull.head(2).iterrows():\n",
    "    path = images_path + x['image']\n",
    "    html = \"<h4>Image : \"+x['image']+\" &nbsp;&nbsp;&nbsp; (Whiteness : \" + str(x['whiteness']) +\")</h4>\"\n",
    "    display(HTML(html))\n",
    "    display(IMG.open(path).resize((300,300), IMG.ANTIALIAS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d2150622-7eea-462c-b6b2-3bc21e51c1f6",
    "_uuid": "2a521a22a76e75937aff2476579f1fd473ce7a68",
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 7,
        "hidden": false,
        "row": 101,
        "width": 12
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "## 3. Uniform Images (with no pixel variations)\n",
    "\n",
    "### Feature 3 - Average Pixel Width (using edge detection)\n",
    "\n",
    "Some images may contain no pixel variation and are entirely uniform. Average Pixel Width is a measure which indicates the amount of edges present in the image. If this number comes out to be very low, then the image is most likely a uniform image and may not represent right content. \n",
    "\n",
    "To compute this measure, I am using skimage's Canny Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "616df65d-8954-4361-ad24-1ce5c6252ead",
    "_kg_hide-input": true,
    "_uuid": "ad37cc1d00a1ca112be728f1002fd1bb399c6543",
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 5,
        "hidden": false,
        "row": 54,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "im1 = IMG.open(images_path+'000c21f80-1.jpg')\n",
    "im2 = im1.convert(mode='L')\n",
    "im = np.asarray(im2)\n",
    "\n",
    "edges1 = feature.canny(im, sigma=1)\n",
    "edges2 = feature.canny(im, sigma=3)\n",
    "\n",
    "# display results\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=3, figsize=(8, 3), sharex=True, sharey=True)\n",
    "\n",
    "ax1.imshow(im, cmap=plt.cm.gray)\n",
    "ax1.axis('off')\n",
    "ax1.set_title('noisy image', fontsize=20)\n",
    "\n",
    "ax2.imshow(edges1, cmap=plt.cm.gray)\n",
    "ax2.axis('off')\n",
    "ax2.set_title('Canny filter, $\\sigma=1$', fontsize=20)\n",
    "\n",
    "ax3.imshow(edges2, cmap=plt.cm.gray)\n",
    "ax3.axis('off')\n",
    "ax3.set_title('Canny filter, $\\sigma=3$', fontsize=20)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "10461e41-46ce-409f-835f-eb654000656d",
    "_uuid": "110a8eea49567c004c98ae6e936bf0c2a91c09c1",
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 7,
        "hidden": false,
        "row": 54,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def average_pixel_width(img):\n",
    "    path = images_path + img \n",
    "    im = IMG.open(path)    \n",
    "    im_array = np.asarray(im.convert(mode='L'))\n",
    "    edges_sigma1 = feature.canny(im_array, sigma=3)\n",
    "    apw = (float(np.sum(edges_sigma1)) / (im.size[0]*im.size[1]))\n",
    "    return apw*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "10c37cfd-3e67-4fc1-bfa7-38e46753c2ae",
    "_kg_hide-input": true,
    "_uuid": "0408abec0f3556514f5a1919e8562c89e0a55dde"
   },
   "outputs": [],
   "source": [
    "features['average_pixel_width'] = features['image'].apply(average_pixel_width)\n",
    "tempdf = features.sort_values('average_pixel_width').head()\n",
    "tempdf "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d2f12b86-5c88-4a6a-87cc-f741f5033957",
    "_uuid": "4d246893ad53122ecd36dd263046142e9003ab8a"
   },
   "source": [
    "Lets plot some images having very low average pixel width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1448292a-2fb5-4837-8120-5e2f7a944fea",
    "_kg_hide-input": true,
    "_uuid": "255c2cdcf648df5511327e498433d95ebfce5748",
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 62,
        "hidden": false,
        "row": 108,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "for j,x in tempdf.head(6).iterrows():\n",
    "    path = images_path + x['image']\n",
    "    html = \"<h4>Image : \"+x['image']+\" &nbsp;&nbsp;&nbsp; (Average Pixel Width : \" + str(x['average_pixel_width']) +\")</h4>\"\n",
    "    display(HTML(html))\n",
    "    display(IMG.open(path).resize((300,300), IMG.ANTIALIAS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "10fdbda1-c082-47cd-89bd-74349e720da1",
    "_uuid": "b49cb2ad57ec1ae349ba8c44a0d95e79b8176cf0",
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 5,
        "hidden": false,
        "row": 170,
        "width": 12
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "Above images are most likely nosie and have low average pixel width values.\n",
    "\n",
    "## 4. What are the key colors used in the image ?\n",
    "\n",
    "Colors used in the images play a significant role in garnering the attraction from users. Additional features related to colors such as Dominant and Average colors can be created. \n",
    "\n",
    "### Feature 4.1 - Dominant Color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "60580391-e3f4-4a07-bb32-4b54586692f3",
    "_uuid": "7eff644388288eadb616c67550383e584726084a",
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 11,
        "hidden": false,
        "row": 77,
        "width": 5
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "# def get_dominant_color(img):\n",
    "#     path = images_path + img \n",
    "#     img = cv2.imread(path)\n",
    "#     arr = np.float32(img)\n",
    "#     pixels = arr.reshape((-1, 3))\n",
    "\n",
    "#     n_colors = 5\n",
    "#     criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 200, .1)\n",
    "#     flags = cv2.KMEANS_RANDOM_CENTERS\n",
    "#     _, labels, centroids = cv2.kmeans(pixels, n_colors, None, criteria, 10, flags)\n",
    "\n",
    "#     palette = np.uint8(centroids)\n",
    "#     quantized = palette[labels.flatten()]\n",
    "#     quantized = quantized.reshape(img.shape)\n",
    "\n",
    "#     dominant_color = palette[np.argmax(itemfreq(labels)[:, -1])]\n",
    "#     return dominant_color\n",
    "\n",
    "# features['dominant_color'] = features['image'].apply(get_dominant_color)\n",
    "# features.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d6f04d44-3232-4c1a-9eec-204c663ba769",
    "_uuid": "5674845fa267cd9be5512323ea2a2656dd5a67f2",
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 5,
        "hidden": false,
        "row": 175,
        "width": 12
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "Lets split the dominant color's RGB values to separate features \n",
    "\n",
    "- Feature 4.1.1 dominant_red value\n",
    "- Feature 4.1.2 dominant_green value\n",
    "- Feature 4.1.3 dominant_blue value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ebe2559c-1b9f-4aee-9be4-5401e3ad5106",
    "_uuid": "4b1a36b983440352d38415805775ecea36107273",
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 7,
        "hidden": false,
        "row": 59,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "# features['dominant_red'] = features['dominant_color'].apply(lambda x: x[0]) / 255\n",
    "# features['dominant_green'] = features['dominant_color'].apply(lambda x: x[1]) / 255\n",
    "# features['dominant_blue'] = features['dominant_color'].apply(lambda x: x[2]) / 255\n",
    "# features[['dominant_red', 'dominant_green', 'dominant_blue']].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "714eba9e-f82d-470e-9587-44af5e56a0ca",
    "_uuid": "f7592cadd7cfed432db20aa1635a7ad5c51eea96",
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 4,
        "hidden": false,
        "row": 61,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "### Feature 4.2 Average Color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c198f9fe-9f28-4304-a121-d11af52ee5d7",
    "_uuid": "5a20ae6b7face06ba53f506aad059062d0ce7f6e",
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 11,
        "hidden": false,
        "row": 180,
        "width": 9
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "# def get_average_color(img):\n",
    "#     path = images_path + img \n",
    "#     img = cv2.imread(path)\n",
    "#     average_color = [img[:, :, i].mean() for i in range(img.shape[-1])]\n",
    "#     return average_color\n",
    "\n",
    "# features['average_color'] = features['image'].apply(get_average_color)\n",
    "# features.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "14bfd944-f2cc-4472-8fd8-1a155b8cf975",
    "_uuid": "a4d855fea8aa0649ef5478908b99d6d63699967b",
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 7,
        "hidden": false,
        "row": 88,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "# features['average_red'] = features['average_color'].apply(lambda x: x[0]) / 255\n",
    "# features['average_green'] = features['average_color'].apply(lambda x: x[1]) / 255\n",
    "# features['average_blue'] = features['average_color'].apply(lambda x: x[2]) / 255\n",
    "# features[['average_red', 'average_green', 'average_blue']].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "52ee862a-5932-4e33-9cc2-c821e8f60471",
    "_uuid": "ad345e6c8c9b502e26c6038bdc17e621b5981774",
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 5,
        "hidden": false,
        "row": 191,
        "width": 12
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "## 5. Dimensions of the Image \n",
    "\n",
    "Too Big Images or Too Small Images might not be very good for generating good attraction. Users may skip viewing a very large or very small sized image. Hence for advertisers it is important to set precise dimensions and size of the image. Hence we can create additional features. \n",
    "\n",
    "- Image width\n",
    "- Image height\n",
    "- Image size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6f0917eb-cadf-460f-9996-55071a1808a8",
    "_uuid": "023cb77036bff2cf1dd613814779b60ff7b0f507",
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def getSize(filename):\n",
    "    filename = original_images_path + filename\n",
    "    st = os.stat(filename)\n",
    "    return st.st_size\n",
    "\n",
    "def getDimensions(filename):\n",
    "    filename = original_images_path + filename\n",
    "    img_size = IMG.open(filename).size\n",
    "    return img_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "efafe14e-52fb-409e-9588-92b62643edfa",
    "_uuid": "1eab34994a899bec9a35c40505d77105e7524b8d",
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "features['image_size'] = features['image'].apply(getSize)\n",
    "features['temp_size'] = features['image'].apply(getDimensions)\n",
    "features['width'] = features['temp_size'].apply(lambda x : x[0])\n",
    "features['height'] = features['temp_size'].apply(lambda x : x[1])\n",
    "#features = features.drop(['temp_size', 'average_color', 'dominant_color'], axis=1)\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to file\n",
    "features.to_csv('features-train.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5957b9c9-f56d-4dca-8191-494010c95122",
    "_uuid": "8d6e3013322b525cca9b5c394037063d69264a1c"
   },
   "source": [
    "## 6. Is the image too Blurry \n",
    "\n",
    "### Feature 6 - Image Blurrness\n",
    "\n",
    "To measure the image blurrness, I refered to the following paper: \"Diatom Autofocusing in Brightfield Microscopy: A Comparative Study\". \n",
    "\n",
    "In this paper the author Pech-Pacheco et al. has provided variance of the Laplacian Filter which can be used to measure if the image blurryness score.\n",
    "\n",
    "In this technique, the single channel of an image is convolved  with the the laplacian filter. If the specified value is less than a threshold value, then image is blurry otherwise not.  \n",
    "\n",
    "![](https://www.pyimagesearch.com/wp-content/uploads/2015/09/detecting_blur_laplacian.png)\n",
    "\n",
    "-  Paper Link : http://optica.csic.es/papers/icpr2k.pdf  \n",
    "-  Reference : https://www.pyimagesearch.com/2015/09/07/blur-detection-with-opencv/\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "35dd5e89-2cee-465d-b130-65d585b2085b",
    "_uuid": "1e8b1d93a2fd13b4596ee438de577648f106fcaa"
   },
   "outputs": [],
   "source": [
    "def get_blurrness_score(image):\n",
    "    path =  images_path + image \n",
    "    image = cv2.imread(path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    fm = cv2.Laplacian(image, cv2.CV_64F).var()\n",
    "    return fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0ce0b212-9286-4a05-bf91-d983af10ff88",
    "_uuid": "fd9726fd33bfcce9be4c5c5ee1e19c471df8b3e6"
   },
   "outputs": [],
   "source": [
    "features['blurrness'] = features['image'].apply(get_blurrness_score)\n",
    "features[['image','blurrness']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0a4edead-46c7-4a80-b8ec-57d7b53d29d4",
    "_uuid": "4b5142c9c3c79fa53d0848d3f8001392c888230b"
   },
   "outputs": [],
   "source": [
    "tempdf = features.sort_values('blurrness')\n",
    "for y,x in tempdf.head(5).iterrows():\n",
    "    path = images_path + x['image']\n",
    "    html = \"<h4>Image : \"+x['image']+\" &nbsp;&nbsp;&nbsp; (Blurrness : \" + str(x['blurrness']) +\")</h4>\"\n",
    "    display(HTML(html))\n",
    "    display(IMG.open(path).resize((300,300), IMG.ANTIALIAS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "17ab42cb-dbe5-412e-849c-dc591b86e040",
    "_uuid": "6f4673f3661aece639244f52620598d3a284d83f",
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 9,
        "hidden": false,
        "row": 203,
        "width": 12
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "### Other Ideas about features from Image\n",
    "\n",
    "- No of objects detected \n",
    "- Total Number of Color Present \n",
    "- No. of shapes detected \n",
    "- Amount of Text Present in the image \n",
    "\n",
    "Other great kernels on Image Feature Extraction:\n",
    "\n",
    "1. https://www.kaggle.com/wesamelshamy/ad-image-recognition-and-quality-scoring by wesamelshamy  \n",
    "2. https://www.kaggle.com/peterhurford/image-feature-engineering by peterhurford  "
   ]
  }
 ],
 "metadata": {
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "grid_default",
    "version": 1,
    "views": {
     "grid_default": {
      "cellMargin": 10,
      "defaultCellHeight": 20,
      "maxColumns": 12,
      "name": "grid",
      "type": "grid"
     },
     "report_default": {
      "name": "report",
      "type": "report"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
