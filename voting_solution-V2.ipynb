{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pydot\n",
    "\n",
    "from sklearn.externals.six import StringIO\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "import score_solution\n",
    "from sklearn.metrics import cohen_kappa_score, make_scorer\n",
    "\n",
    "train_data = pd.read_csv('all_train_data_V4.csv', dtype={'PetID': str})\n",
    "test_data = pd.read_csv('all_test_data_V4.csv', dtype={'PetID': str})\n",
    "\n",
    "adoptionSpeed = train_data['AdoptionSpeed'] \n",
    "del train_data['AdoptionSpeed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = test_data[['PetID']]\n",
    "\n",
    "del train_data[\"Name\"]\n",
    "del train_data[\"RescuerID\"]\n",
    "del train_data[\"Description\"]\n",
    "del train_data[\"PetID\"]\n",
    "\n",
    "\n",
    "del test_data[\"Name\"]\n",
    "del test_data[\"RescuerID\"]\n",
    "del test_data[\"Description\"]\n",
    "del test_data[\"PetID\"]\n",
    "\n",
    "train_data = train_data.fillna(0)\n",
    "test_data = test_data.fillna(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 4, 4, ..., 2, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# scaler = StandardScaler()  \n",
    "# # fit only on training data\n",
    "# scaler.fit(train_data)  \n",
    "# train_data = scaler.transform(train_data)  \n",
    "# # apply same transformation to test data\n",
    "# test_data = scaler.transform(test_data)  \n",
    "\n",
    "# pca = PCA()  \n",
    "# train_data = pca.fit_transform(train_data)  \n",
    "# test_data = pca.transform(test_data)  \n",
    "# explained_variance = pca.explained_variance_ratio_  \n",
    "# print(explained_variance)\n",
    "\n",
    "mlp_model = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                     hidden_layer_sizes=(15,), random_state=1)\n",
    "\n",
    "gbc_model = GradientBoostingClassifier(n_estimators=1000, learning_rate=0.1,\n",
    "     max_depth=2)\n",
    "\n",
    "agb_model = AdaBoostClassifier(learning_rate=0.1, n_estimators=1000,\n",
    "                           algorithm='SAMME.R', base_estimator=DecisionTreeClassifier(max_depth=2))\n",
    "\n",
    "extra_model = ExtraTreesClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=2, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=None,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False)\n",
    "\n",
    "rf_model = RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
    "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=2, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=None,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False)\n",
    "\n",
    "bagging_model = BaggingClassifier(DecisionTreeClassifier(), n_estimators = 1000,\n",
    "                            max_samples=0.5, max_features=0.5)\n",
    "\n",
    "parameters = {\n",
    "    'learning_rate':0.01,'max_depth':4,\n",
    "    'subsample':0.8,'objective':'binary:logistic',\n",
    "    'num_class':5, 'n_jobs':4,  'n_estimators':1000}\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=0.5, gamma=0, learning_rate=0.03, max_delta_step=0,\n",
    "       max_depth=3, min_child_weight=1, missing=None, n_estimators=650,\n",
    "       n_jobs=1, nthread=None, objective='multi:softprob', random_state=0,\n",
    "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "       silent=True, subsample=0.8)\n",
    "\n",
    "classifiers = [\n",
    "    ('gbc', gbc_model), ('agb', agb_model),\n",
    "    ('extra', extra_model), ('rf', rf_model),\n",
    "    ('bagging', bagging_model), (\"xgb\", xgb_model),\n",
    "    ('mlp', mlp_model)\n",
    "]\n",
    "\n",
    "voting_model = VotingClassifier(estimators=classifiers, voting='hard')\n",
    "\n",
    "voting_model.fit(train_data, adoptionSpeed)\n",
    "\n",
    "ans = voting_model.predict(test_data)\n",
    "\n",
    "ans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dict = {}\n",
    "\n",
    "for i in range (0, len(test_ids['PetID'])):\n",
    "    res_dict[test_ids.iloc[i]['PetID']] = ans.item(i)\n",
    "\n",
    "submission = pd.DataFrame({'PetID': test_ids['PetID'], 'AdoptionSpeed': ans})\n",
    "submission.to_csv('submission-V3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "CSV_PATH = 'C:/Users/madad/Documents/dataset/sample_submission.csv'\n",
    "fin_df = pd.read_csv(CSV_PATH, header=0, usecols=['PetID'])\n",
    "\n",
    "fin_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sub_df = pd.DataFrame()\n",
    "\n",
    "for index, row in fin_df.iterrows():\n",
    "\n",
    "    petId = str(row['PetID'])\n",
    "    \n",
    "    if str(petId) in res_dict.keys():\n",
    "        row['PetID'] = petId\n",
    "        row['AdoptionSpeed'] = res_dict[petId]\n",
    "    else:\n",
    "        print(petId)\n",
    "        row['PetID'] = petId\n",
    "        row['AdoptionSpeed'] = 3\n",
    "    \n",
    "    sub_df = sub_df.append([row],ignore_index=True)\n",
    "        \n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df.to_csv('fin-sub-v2.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
